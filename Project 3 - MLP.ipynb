{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = pd.read_csv('sp500_dataset.csv')\n",
    "aapl = pd.read_csv('aapl_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.set_index('Date',inplace=True)\n",
    "aapl.set_index('Date',inplace=True)\n",
    "sp.drop(['Volume','next_2d_var'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Return</th>\n",
       "      <th>volume_ch</th>\n",
       "      <th>hilo</th>\n",
       "      <th>intraday</th>\n",
       "      <th>2dvar</th>\n",
       "      <th>5dvar</th>\n",
       "      <th>20dvar</th>\n",
       "      <th>60dvar</th>\n",
       "      <th>vol_next</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-03-31</th>\n",
       "      <td>-0.003273</td>\n",
       "      <td>0.097758</td>\n",
       "      <td>0.007540</td>\n",
       "      <td>-0.001980</td>\n",
       "      <td>0.002344</td>\n",
       "      <td>0.003392</td>\n",
       "      <td>0.004732</td>\n",
       "      <td>0.008946</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-01</th>\n",
       "      <td>0.007414</td>\n",
       "      <td>-0.106475</td>\n",
       "      <td>0.009174</td>\n",
       "      <td>0.005866</td>\n",
       "      <td>0.007557</td>\n",
       "      <td>0.004360</td>\n",
       "      <td>0.004863</td>\n",
       "      <td>0.008984</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-05</th>\n",
       "      <td>0.007928</td>\n",
       "      <td>-0.031259</td>\n",
       "      <td>0.007652</td>\n",
       "      <td>0.007406</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.004937</td>\n",
       "      <td>0.004252</td>\n",
       "      <td>0.009033</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-06</th>\n",
       "      <td>0.001684</td>\n",
       "      <td>0.052700</td>\n",
       "      <td>0.007635</td>\n",
       "      <td>0.002892</td>\n",
       "      <td>0.004415</td>\n",
       "      <td>0.004830</td>\n",
       "      <td>0.004220</td>\n",
       "      <td>0.009024</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-07</th>\n",
       "      <td>-0.005877</td>\n",
       "      <td>0.248459</td>\n",
       "      <td>0.010491</td>\n",
       "      <td>-0.004864</td>\n",
       "      <td>0.005346</td>\n",
       "      <td>0.006195</td>\n",
       "      <td>0.004591</td>\n",
       "      <td>0.009059</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Return  volume_ch      hilo  intraday     2dvar     5dvar  \\\n",
       "Date                                                                      \n",
       "2010-03-31 -0.003273   0.097758  0.007540 -0.001980  0.002344  0.003392   \n",
       "2010-04-01  0.007414  -0.106475  0.009174  0.005866  0.007557  0.004360   \n",
       "2010-04-05  0.007928  -0.031259  0.007652  0.007406  0.000364  0.004937   \n",
       "2010-04-06  0.001684   0.052700  0.007635  0.002892  0.004415  0.004830   \n",
       "2010-04-07 -0.005877   0.248459  0.010491 -0.004864  0.005346  0.006195   \n",
       "\n",
       "              20dvar    60dvar  vol_next  \n",
       "Date                                      \n",
       "2010-03-31  0.004732  0.008946      True  \n",
       "2010-04-01  0.004863  0.008984     False  \n",
       "2010-04-05  0.004252  0.009033      True  \n",
       "2010-04-06  0.004220  0.009024      True  \n",
       "2010-04-07  0.004591  0.009059      True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sp.loc[:,'Return':'60dvar']\n",
    "y = to_categorical(sp['vol_next'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 0s 499us/step - loss: 0.7747 - accuracy: 0.4901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2932640b668>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_cols = x.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(50,activation='sigmoid',input_shape=(n_cols,)))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = [50,50,2]\n",
    "act = ['relu','relu','softmax']\n",
    "inp = n_cols\n",
    "opt = 'adam'\n",
    "los = 'categorical_crossentropy'\n",
    "metrics = ['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n,act,inp,opt,los,met): \n",
    "    model = Sequential()\n",
    "    model.add(Dense(n[0],activation=act[0],input_shape=(inp,)))\n",
    "    for i in range(1,len(n)): \n",
    "        model.add(Dense(n[i],activation=act[i]))\n",
    "    model.compile(optimizer=opt,loss=los,metrics=met)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/54 [..............................] - ETA: 0s - loss: 0.6922 - accuracy: 0.6875WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "54/54 [==============================] - 0s 557us/step - loss: 0.6920 - accuracy: 0.5361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2932534c550>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = create_model(n,act,inp,opt,los,metrics)\n",
    "model2.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.6927 - accuracy: 0.5343 - val_loss: 0.6927 - val_accuracy: 0.4966\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.6857 - accuracy: 0.5559 - val_loss: 0.6788 - val_accuracy: 0.5685\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.6691 - accuracy: 0.5885 - val_loss: 0.6644 - val_accuracy: 0.6011\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.6506 - accuracy: 0.6106 - val_loss: 0.6355 - val_accuracy: 0.6784\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.6330 - accuracy: 0.6321 - val_loss: 0.6097 - val_accuracy: 0.6947\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5977 - accuracy: 0.6769 - val_loss: 0.5840 - val_accuracy: 0.7110\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5950 - accuracy: 0.6764 - val_loss: 0.5884 - val_accuracy: 0.6784\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5868 - accuracy: 0.6880 - val_loss: 0.5594 - val_accuracy: 0.7232\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5757 - accuracy: 0.6944 - val_loss: 0.5515 - val_accuracy: 0.7476\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5770 - accuracy: 0.6903 - val_loss: 0.5695 - val_accuracy: 0.7015\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.5701 - accuracy: 0.7026 - val_loss: 0.5589 - val_accuracy: 0.7259\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5755 - accuracy: 0.7014 - val_loss: 0.5793 - val_accuracy: 0.6689\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.5747 - accuracy: 0.7026 - val_loss: 0.5616 - val_accuracy: 0.7408\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.5612 - accuracy: 0.7090 - val_loss: 0.5864 - val_accuracy: 0.6730\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5686 - accuracy: 0.6973 - val_loss: 0.6170 - val_accuracy: 0.6445\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5881 - accuracy: 0.6769 - val_loss: 0.5632 - val_accuracy: 0.6988\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5559 - accuracy: 0.7130 - val_loss: 0.5481 - val_accuracy: 0.7178\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5543 - accuracy: 0.7177 - val_loss: 0.5685 - val_accuracy: 0.6879\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5654 - accuracy: 0.7148 - val_loss: 0.6051 - val_accuracy: 0.6594\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5547 - accuracy: 0.7159 - val_loss: 0.5550 - val_accuracy: 0.7232\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5518 - accuracy: 0.7165 - val_loss: 0.5306 - val_accuracy: 0.7313\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5579 - accuracy: 0.7113 - val_loss: 0.5661 - val_accuracy: 0.7164\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5805 - accuracy: 0.6816 - val_loss: 0.5595 - val_accuracy: 0.7313\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5484 - accuracy: 0.7212 - val_loss: 0.5372 - val_accuracy: 0.7408\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5566 - accuracy: 0.7177 - val_loss: 0.5418 - val_accuracy: 0.7368\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5506 - accuracy: 0.7078 - val_loss: 0.6059 - val_accuracy: 0.6581\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.5607 - accuracy: 0.6997 - val_loss: 0.5963 - val_accuracy: 0.6676\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5464 - accuracy: 0.7340 - val_loss: 0.5217 - val_accuracy: 0.7585\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5454 - accuracy: 0.7224 - val_loss: 0.5485 - val_accuracy: 0.7069\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5519 - accuracy: 0.7148 - val_loss: 0.5269 - val_accuracy: 0.7598\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5332 - accuracy: 0.7311 - val_loss: 0.5221 - val_accuracy: 0.7531\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5368 - accuracy: 0.7218 - val_loss: 0.5311 - val_accuracy: 0.7463\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5325 - accuracy: 0.7299 - val_loss: 0.5843 - val_accuracy: 0.6852\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5381 - accuracy: 0.7189 - val_loss: 0.5420 - val_accuracy: 0.7395\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5464 - accuracy: 0.7148 - val_loss: 0.6283 - val_accuracy: 0.6581\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5516 - accuracy: 0.7078 - val_loss: 0.5198 - val_accuracy: 0.7571\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5320 - accuracy: 0.7305 - val_loss: 0.5188 - val_accuracy: 0.7476\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5437 - accuracy: 0.7311 - val_loss: 0.5304 - val_accuracy: 0.7313\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5406 - accuracy: 0.7276 - val_loss: 0.5285 - val_accuracy: 0.7531\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5357 - accuracy: 0.7334 - val_loss: 0.5250 - val_accuracy: 0.7463\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5381 - accuracy: 0.7258 - val_loss: 0.5321 - val_accuracy: 0.7300\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5237 - accuracy: 0.7392 - val_loss: 0.5184 - val_accuracy: 0.7612\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5251 - accuracy: 0.7375 - val_loss: 0.5583 - val_accuracy: 0.6974\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5253 - accuracy: 0.7334 - val_loss: 0.5232 - val_accuracy: 0.7571\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5301 - accuracy: 0.7311 - val_loss: 0.6204 - val_accuracy: 0.6621\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5316 - accuracy: 0.7288 - val_loss: 0.5426 - val_accuracy: 0.7218\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5376 - accuracy: 0.7293 - val_loss: 0.5214 - val_accuracy: 0.7544\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5332 - accuracy: 0.7317 - val_loss: 0.5244 - val_accuracy: 0.7639\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5290 - accuracy: 0.7305 - val_loss: 0.5281 - val_accuracy: 0.7381\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5279 - accuracy: 0.7276 - val_loss: 0.5120 - val_accuracy: 0.7612\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5264 - accuracy: 0.7258 - val_loss: 0.5240 - val_accuracy: 0.7503\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5192 - accuracy: 0.7398 - val_loss: 0.5224 - val_accuracy: 0.7259\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5249 - accuracy: 0.7404 - val_loss: 0.5227 - val_accuracy: 0.7408\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5218 - accuracy: 0.7392 - val_loss: 0.5261 - val_accuracy: 0.7503\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5314 - accuracy: 0.7241 - val_loss: 0.5268 - val_accuracy: 0.7341\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5269 - accuracy: 0.7363 - val_loss: 0.5622 - val_accuracy: 0.7015\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5279 - accuracy: 0.7357 - val_loss: 0.5236 - val_accuracy: 0.7381\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5156 - accuracy: 0.7386 - val_loss: 0.5205 - val_accuracy: 0.7585\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5216 - accuracy: 0.7439 - val_loss: 0.5791 - val_accuracy: 0.6934\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5225 - accuracy: 0.7410 - val_loss: 0.5295 - val_accuracy: 0.7368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29356cbdb38>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = [1028,1028,2]\n",
    "act = ['relu','relu','softmax']\n",
    "inp = n_cols\n",
    "opt = 'adam'\n",
    "los = 'categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "model3 = create_model(n,act,inp,opt,los,metrics)\n",
    "esm = EarlyStopping(patience=10)\n",
    "model3.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=100,callbacks=[esm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.8774 - accuracy: 0.4924 - val_loss: 0.8374 - val_accuracy: 0.4708\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.7534 - accuracy: 0.5087 - val_loss: 0.9615 - val_accuracy: 0.4708\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.7527 - accuracy: 0.5041 - val_loss: 0.7110 - val_accuracy: 0.4708\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.7176 - accuracy: 0.5017 - val_loss: 0.7025 - val_accuracy: 0.5292\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.7133 - accuracy: 0.4994 - val_loss: 0.6975 - val_accuracy: 0.5292\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.7025 - accuracy: 0.5250 - val_loss: 0.7006 - val_accuracy: 0.5292\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.7088 - accuracy: 0.5047 - val_loss: 0.6921 - val_accuracy: 0.5292\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.6970 - accuracy: 0.5000 - val_loss: 0.6910 - val_accuracy: 0.5305\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.7069 - accuracy: 0.4965 - val_loss: 0.6910 - val_accuracy: 0.5292\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.7082 - accuracy: 0.4994 - val_loss: 0.6958 - val_accuracy: 0.4708\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.7137 - accuracy: 0.5169 - val_loss: 0.6945 - val_accuracy: 0.4708\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.7033 - accuracy: 0.5227 - val_loss: 0.7102 - val_accuracy: 0.4708\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.6995 - accuracy: 0.4907 - val_loss: 0.6957 - val_accuracy: 0.4708\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.6941 - accuracy: 0.5186 - val_loss: 0.7052 - val_accuracy: 0.4708\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.7040 - accuracy: 0.5134 - val_loss: 0.6912 - val_accuracy: 0.5292\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.7045 - accuracy: 0.5099 - val_loss: 0.7250 - val_accuracy: 0.4708\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.7093 - accuracy: 0.4977 - val_loss: 0.7072 - val_accuracy: 0.4708\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.7165 - accuracy: 0.5029 - val_loss: 0.7117 - val_accuracy: 0.4708\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.7022 - accuracy: 0.4948 - val_loss: 0.6912 - val_accuracy: 0.5292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2935a741cc0>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = [1028,1028,2]\n",
    "act = ['sigmoid','sigmoid','softmax']\n",
    "inp = n_cols\n",
    "opt = 'adam'\n",
    "los = 'categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "model4 = create_model(n,act,inp,opt,los,metrics)\n",
    "esm = EarlyStopping(patience=10)\n",
    "model4.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=100,callbacks=[esm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.save('model3_spx.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_train,spx_test = sp.loc[:,'Return':'60dvar'].iloc[:1850],sp.loc[:,'Return':'60dvar'].iloc[1850:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_train,spy_test = sp.loc[:,'vol_next'].iloc[:1850],sp.loc[:,'vol_next'].iloc[1850:]\n",
    "spy_train,spy_test = to_categorical(spy_train),to_categorical(spy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.6922 - accuracy: 0.5297 - val_loss: 0.6845 - val_accuracy: 0.5884\n",
      "Epoch 2/100\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.6802 - accuracy: 0.5649 - val_loss: 0.6595 - val_accuracy: 0.6050\n",
      "Epoch 3/100\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.6517 - accuracy: 0.6216 - val_loss: 0.6244 - val_accuracy: 0.6744\n",
      "Epoch 4/100\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.6372 - accuracy: 0.6281 - val_loss: 0.6100 - val_accuracy: 0.6512\n",
      "Epoch 5/100\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.6150 - accuracy: 0.6541 - val_loss: 0.5782 - val_accuracy: 0.6926\n",
      "Epoch 6/100\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.5949 - accuracy: 0.6805 - val_loss: 0.5586 - val_accuracy: 0.7223\n",
      "Epoch 7/100\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.6033 - accuracy: 0.6708 - val_loss: 0.6070 - val_accuracy: 0.6264\n",
      "Epoch 8/100\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.5764 - accuracy: 0.6892 - val_loss: 0.5573 - val_accuracy: 0.7207\n",
      "Epoch 9/100\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.5647 - accuracy: 0.7049 - val_loss: 0.5431 - val_accuracy: 0.7124\n",
      "Epoch 10/100\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.5728 - accuracy: 0.7038 - val_loss: 0.6520 - val_accuracy: 0.6331\n",
      "Epoch 11/100\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.5799 - accuracy: 0.6886 - val_loss: 0.5650 - val_accuracy: 0.6826\n",
      "Epoch 12/100\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.5765 - accuracy: 0.6962 - val_loss: 0.5463 - val_accuracy: 0.7207\n",
      "Epoch 13/100\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.5543 - accuracy: 0.7249 - val_loss: 0.5372 - val_accuracy: 0.7339\n",
      "Epoch 14/100\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.5560 - accuracy: 0.7189 - val_loss: 0.5501 - val_accuracy: 0.7008\n",
      "Epoch 15/100\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.5659 - accuracy: 0.7097 - val_loss: 0.5627 - val_accuracy: 0.7041\n",
      "Epoch 16/100\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.5533 - accuracy: 0.7200 - val_loss: 0.5326 - val_accuracy: 0.7140\n",
      "Epoch 17/100\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.5481 - accuracy: 0.7265 - val_loss: 0.5405 - val_accuracy: 0.7058\n",
      "Epoch 18/100\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.5569 - accuracy: 0.7141 - val_loss: 0.5250 - val_accuracy: 0.7421\n",
      "Epoch 19/100\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.5514 - accuracy: 0.7103 - val_loss: 0.6165 - val_accuracy: 0.6545\n",
      "Epoch 20/100\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.5516 - accuracy: 0.7184 - val_loss: 0.5676 - val_accuracy: 0.6992\n",
      "Epoch 21/100\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.5589 - accuracy: 0.7157 - val_loss: 0.5307 - val_accuracy: 0.7339\n",
      "Epoch 22/100\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.5471 - accuracy: 0.7238 - val_loss: 0.5201 - val_accuracy: 0.7289\n",
      "Epoch 23/100\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.5430 - accuracy: 0.7373 - val_loss: 0.5741 - val_accuracy: 0.6992\n",
      "Epoch 24/100\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.5463 - accuracy: 0.7319 - val_loss: 0.5266 - val_accuracy: 0.7306\n",
      "Epoch 25/100\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.5334 - accuracy: 0.7373 - val_loss: 0.5165 - val_accuracy: 0.7488\n",
      "Epoch 26/100\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.5383 - accuracy: 0.7265 - val_loss: 0.5218 - val_accuracy: 0.7339\n",
      "Epoch 27/100\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.5535 - accuracy: 0.7205 - val_loss: 0.5555 - val_accuracy: 0.6975\n",
      "Epoch 28/100\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.5279 - accuracy: 0.7395 - val_loss: 0.5871 - val_accuracy: 0.6909\n",
      "Epoch 29/100\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.5316 - accuracy: 0.7427 - val_loss: 0.5145 - val_accuracy: 0.7174\n",
      "Epoch 30/100\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.5290 - accuracy: 0.7281 - val_loss: 0.6067 - val_accuracy: 0.6545\n",
      "Epoch 31/100\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.5415 - accuracy: 0.7265 - val_loss: 0.5427 - val_accuracy: 0.7157\n",
      "Epoch 32/100\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.5308 - accuracy: 0.7362 - val_loss: 0.5294 - val_accuracy: 0.7207\n",
      "Epoch 33/100\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.5217 - accuracy: 0.7411 - val_loss: 0.5282 - val_accuracy: 0.7140\n",
      "Epoch 34/100\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.5410 - accuracy: 0.7422 - val_loss: 0.5226 - val_accuracy: 0.7124\n",
      "Epoch 35/100\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.5393 - accuracy: 0.7232 - val_loss: 0.5230 - val_accuracy: 0.7124\n",
      "Epoch 36/100\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.5388 - accuracy: 0.7384 - val_loss: 0.5215 - val_accuracy: 0.7339\n",
      "Epoch 37/100\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.5444 - accuracy: 0.7249 - val_loss: 0.5173 - val_accuracy: 0.7074\n",
      "Epoch 38/100\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.5272 - accuracy: 0.7319 - val_loss: 0.5435 - val_accuracy: 0.7190\n",
      "Epoch 39/100\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.5212 - accuracy: 0.7454 - val_loss: 0.5229 - val_accuracy: 0.7207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2935722bf60>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = [1028,1028,2]\n",
    "act = ['relu','relu','softmax']\n",
    "inp = n_cols\n",
    "opt = 'adam'\n",
    "los = 'categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "model5 = create_model(n,act,inp,opt,los,metrics)\n",
    "esm = EarlyStopping(patience=10)\n",
    "model5.fit(spx_train,spy_train,validation_data=(spx_test,spy_test),epochs=100,callbacks=[esm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vix = pd.read_csv('vix.csv')\n",
    "vix.set_index('Date')\n",
    "vix['Return'] = vix['Close'].pct_change()\n",
    "vix['hilo'] = vix['High']/vix['Low']\n",
    "\n",
    "vix.dropna(inplace=True)\n",
    "\n",
    "vix.set_index('Date',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "spv = sp.join(vix[['Return','hilo']],lsuffix='_vix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "spvx = spv.drop('vol_next',axis=1)\n",
    "spvy = spv['vol_next']\n",
    "spvy = to_categorical(spvy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "spvx_train,spvx_test = spvx.iloc[:1850],spvx.iloc[1850:]\n",
    "spvy_train,spvy_test = spvy[:1850],spvy[1850:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.6960 - accuracy: 0.5087 - val_loss: 0.6950 - val_accuracy: 0.5081\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.6898 - accuracy: 0.5243 - val_loss: 0.6979 - val_accuracy: 0.4865\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.6856 - accuracy: 0.5580 - val_loss: 0.7001 - val_accuracy: 0.5243\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6818 - accuracy: 0.5670 - val_loss: 0.7188 - val_accuracy: 0.4973\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.6866 - accuracy: 0.5622 - val_loss: 0.7015 - val_accuracy: 0.5243\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.6813 - accuracy: 0.5724 - val_loss: 0.6887 - val_accuracy: 0.5514\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6738 - accuracy: 0.5844 - val_loss: 0.6847 - val_accuracy: 0.5514\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6663 - accuracy: 0.5838 - val_loss: 0.6882 - val_accuracy: 0.5243\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.6384 - accuracy: 0.6270 - val_loss: 0.6658 - val_accuracy: 0.6054\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.6532 - accuracy: 0.6198 - val_loss: 0.6752 - val_accuracy: 0.5730\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6109 - accuracy: 0.6769 - val_loss: 0.6488 - val_accuracy: 0.6432\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6139 - accuracy: 0.6637 - val_loss: 0.6902 - val_accuracy: 0.5243\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.5916 - accuracy: 0.6907 - val_loss: 0.6850 - val_accuracy: 0.5676\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5974 - accuracy: 0.6865 - val_loss: 0.6258 - val_accuracy: 0.7081\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.5803 - accuracy: 0.6967 - val_loss: 0.6917 - val_accuracy: 0.5730\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5858 - accuracy: 0.6919 - val_loss: 0.7934 - val_accuracy: 0.4865\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5762 - accuracy: 0.6943 - val_loss: 0.6175 - val_accuracy: 0.6486\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.5659 - accuracy: 0.6955 - val_loss: 0.7257 - val_accuracy: 0.5730\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.5682 - accuracy: 0.7009 - val_loss: 0.6528 - val_accuracy: 0.6162\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.5774 - accuracy: 0.6985 - val_loss: 0.6721 - val_accuracy: 0.5351\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5511 - accuracy: 0.7141 - val_loss: 0.6093 - val_accuracy: 0.7189\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.5723 - accuracy: 0.6961 - val_loss: 0.6961 - val_accuracy: 0.5946\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.5754 - accuracy: 0.6919 - val_loss: 0.6471 - val_accuracy: 0.6270\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5599 - accuracy: 0.7087 - val_loss: 0.6274 - val_accuracy: 0.6919\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5606 - accuracy: 0.7165 - val_loss: 0.6163 - val_accuracy: 0.6919\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5437 - accuracy: 0.7237 - val_loss: 0.6869 - val_accuracy: 0.6108\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5479 - accuracy: 0.7183 - val_loss: 0.6241 - val_accuracy: 0.6541\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5569 - accuracy: 0.7165 - val_loss: 0.6611 - val_accuracy: 0.6162\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.5805 - accuracy: 0.7027 - val_loss: 0.6784 - val_accuracy: 0.5568\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5644 - accuracy: 0.6997 - val_loss: 0.6135 - val_accuracy: 0.6973\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5415 - accuracy: 0.7351 - val_loss: 0.6593 - val_accuracy: 0.6216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dad3607780>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = [1028,1028,2]\n",
    "act = ['relu','relu','softmax']\n",
    "inp = spvx.shape[1]\n",
    "opt = 'adam'\n",
    "los = 'categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "model6 = create_model(n,act,inp,opt,los,metrics)\n",
    "esm = EarlyStopping(patience=10)\n",
    "model6.fit(spvx_train,spvy_train,validation_split = .1,epochs=100,callbacks=[esm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-23-33268641c81d>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "m6_pred = model6.predict_classes(spvx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spvy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "spvy_check = pd.DataFrame(spvy_test,columns = ['False','True'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "spvy_check['pred'] = m6_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>427 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     False  True  pred\n",
       "0      1.0   0.0     0\n",
       "1      0.0   1.0     1\n",
       "3      0.0   1.0     1\n",
       "4      0.0   1.0     1\n",
       "5      1.0   0.0     0\n",
       "..     ...   ...   ...\n",
       "598    1.0   0.0     0\n",
       "599    0.0   1.0     1\n",
       "601    0.0   1.0     1\n",
       "603    0.0   1.0     1\n",
       "604    0.0   1.0     1\n",
       "\n",
       "[427 rows x 3 columns]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spvy_check[spvy_check['True'] == spvy_check['pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm(n,act,inp,opt,los,met): \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(n[0],input_shape=(inp,)))\n",
    "    for i in range(1,len(n)): \n",
    "        model.add(Dense(n[i],activation=act[i]))\n",
    "    model.compile(optimizer=opt,loss=los,metrics=met)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
